{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# --- 1. Use a Real-World Dataset ---\n",
    "print(\"Loading dataset...\")\n",
    "housing = fetch_california_housing()\n",
    "X = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "y = pd.Series(housing.target, name=\"MedHouseVal\")\n",
    "\n",
    "# --- 2. Perform Data Cleaning ---\n",
    "print(\"\\n--- Data Cleaning ---\")\n",
    "# This dataset is pre-cleaned\n",
    "print(f\"Missing values per column:\\n{X.isnull().sum()}\")\n",
    "\n",
    "# --- 3. Perform Feature Engineering ---\n",
    "print(\"\\n--- Feature Engineering ---\")\n",
    "# Create new features\n",
    "X['Rooms_per_Household'] = X['AveRooms'] / X['AveOccup']\n",
    "X['Bedrms_per_Room'] = X['AveBedrms'] / X['AveRooms']\n",
    "print(\"Added new features 'Rooms_per_Household' and 'Bedrms_per_Room'.\")\n",
    "\n",
    "# --- 4. Split Data ---\n",
    "# We still split into train and test sets.\n",
    "# The K-fold validation will be performed on the *training set*.\n",
    "# The *test set* is held back for a final, one-time evaluation.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining/Validation set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Final Hold-Out Test set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "# --- 5. Create Model Pipeline ---\n",
    "# This is crucial for cross-validation.\n",
    "# We create a 'pipeline' that bundles the steps.\n",
    "# This ensures that data is scaled *inside* each K-fold split,\n",
    "# preventing data leakage (i.e., the training fold \"seeing\"\n",
    "# the validation fold's statistics).\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# --- 6. Model Evaluation with K-Fold Cross-Validation ---\n",
    "print(\"\\n--- K-Fold Cross-Validation ---\")\n",
    "# Define the K-fold strategy (e.g., 5 folds)\n",
    "# shuffle=True ensures the data is mixed before splitting\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Use cross_val_score to perform the K-fold validation.\n",
    "# This function automatically:\n",
    "# 1. Splits the data based on `kf`.\n",
    "# 2. Fits the `pipeline` on the training part of the fold.\n",
    "# 3. Scores the `pipeline` on the validation part of the fold.\n",
    "# 4. Repeats for all 5 folds.\n",
    "# We use 'neg_mean_squared_error' because scikit-learn scoring functions\n",
    "# try to *maximize* a score. We want to *minimize* error, so we use\n",
    "# the negative error, and then flip the sign back later.\n",
    "neg_mse_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert the negative MSE scores back to positive RMSE\n",
    "rmse_scores = np.sqrt(-neg_mse_scores)\n",
    "\n",
    "print(f\"K-Fold RMSE scores for each of the 5 folds: {np.round(rmse_scores, 4)}\")\n",
    "print(f\"Average K-Fold RMSE (on training data): {np.mean(rmse_scores):.4f}\")\n",
    "print(f\"Std. Deviation of K-Fold RMSE: {np.std(rmse_scores):.4f}\")\n",
    "print(\"\\n(This average score is a robust estimate of our model's performance.)\")\n",
    "\n",
    "# --- 7. Final Model Training and Evaluation on Test Set ---\n",
    "print(\"\\n--- Final Model Training & Test Set Evaluation ---\")\n",
    "# Now that we have a good estimate of our model's performance,\n",
    "# we train our *final* model (the pipeline) on the *entire* training set.\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Final model trained on all training data.\")\n",
    "\n",
    "# Finally, we evaluate this single, final model on the\n",
    "# *held-back test set* (data the model has never seen).\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, y_pred)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "print(f\"\\nModel Performance on *Final Test Set*:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {final_rmse:.4f}\")\n",
    "print(f\"(This confirms our K-Fold average: {np.mean(rmse_scores):.4f} is close to our final test score: {final_rmse:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
